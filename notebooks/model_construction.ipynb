{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake news detection\n",
    "\n",
    "**Authors:** Peter Mačinec, Simona Miková"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed/dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use only sample of data for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351651</th>\n",
       "      <td>two people were bitten by a black mammal at a ...</td>\n",
       "      <td>unreliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353884</th>\n",
       "      <td>vaccines are evaluated for safety in studies w...</td>\n",
       "      <td>reliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292248</th>\n",
       "      <td>summary a new study in neuropsychopharmacology...</td>\n",
       "      <td>reliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270158</th>\n",
       "      <td>at the recent conference of the committee for...</td>\n",
       "      <td>reliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236449</th>\n",
       "      <td>the fukushima fallout awareness network ffan i...</td>\n",
       "      <td>unreliable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body       label\n",
       "351651  two people were bitten by a black mammal at a ...  unreliable\n",
       "353884  vaccines are evaluated for safety in studies w...    reliable\n",
       "292248  summary a new study in neuropsychopharmacology...    reliable\n",
       "270158   at the recent conference of the committee for...    reliable\n",
       "236449  the fukushima fallout awareness network ffan i...  unreliable"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels need to be encoded to 0 and 1 (One hot encoding), so our model will be able to understand them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_encoded'] = df['label'].apply(lambda label: 1 if label == 'unreliable' else 0)\n",
    "labels = np.asarray(df['label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the shape of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.preprocessing import get_sequences_and_word_index\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum number of words to preserve will be set to 20000 for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we need to generate sequences and word index table from article body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 282 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequences, word_index = get_sequences_and_word_index(df['body'], max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s have a look at number of unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And shape of input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5387)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading fastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.fasttext import read_fasttext_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read fastText model from .vec file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fasttext = read_fasttext_model('../models/fasttext/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999995, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasttext), len(fasttext['work'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings dimension (length of vectors) will be set to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.preprocessing import get_embeddings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to get embeddings matrix from acquired word indexes and pre-trained embeddings (in our case fastText)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words not found in pre-trained embeddings: 2077\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_matrix = get_embeddings_matrix(word_index, fasttext, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18843, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check if index in sequences match with some randomly choosen word (for example word 'tumor')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will find given word in word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['tumor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check fasttext value for this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0094, -0.2403, -0.0307,  0.066 , -0.1379,  0.0199,  0.004 ,\n",
       "       -0.1303,  0.3053,  0.1848,  0.0616, -0.0794,  0.0279, -0.1055,\n",
       "       -0.1279,  0.0466,  0.0365,  0.0953, -0.091 , -0.1541, -0.5253,\n",
       "        0.0725, -0.0753,  0.2322, -0.0999, -0.0431, -0.1307,  0.0884,\n",
       "       -0.0428, -0.0842, -0.0598, -0.0334, -0.0154,  0.0476,  0.309 ,\n",
       "       -0.1065,  0.1463, -0.0541, -0.0502, -0.0209,  0.0089,  0.1604,\n",
       "        0.1508,  0.153 ,  0.0445,  0.0035, -0.0885, -0.0259,  0.1005,\n",
       "       -0.1053], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext['tumor'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare it to value at given index in embeddings_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.08599998e-01,  2.28300005e-01,  1.42299995e-01,  1.32300004e-01,\n",
       "        4.85000014e-02, -2.95000002e-02, -1.27299994e-01, -1.31000001e-02,\n",
       "        7.50000030e-02,  6.53000027e-02, -1.52600005e-01,  1.40000004e-02,\n",
       "       -3.95999998e-02,  2.01999992e-02, -1.34100005e-01, -1.18000004e-02,\n",
       "        7.63000026e-02,  3.77999991e-02, -1.20099999e-01, -3.29000019e-02,\n",
       "       -5.58399975e-01, -1.53999999e-02,  1.71800002e-01,  6.62999973e-02,\n",
       "        3.04000005e-02,  1.69499993e-01,  9.80000012e-03, -7.73999989e-02,\n",
       "        2.64099985e-01,  1.09600000e-01, -8.61999989e-02, -1.13600001e-01,\n",
       "       -1.74099997e-01,  1.58700004e-01,  2.83600003e-01,  7.51999989e-02,\n",
       "       -3.94000001e-02,  1.29500002e-01,  2.23100007e-01, -3.99999990e-04,\n",
       "       -8.96999985e-02, -4.60000010e-03,  1.36399999e-01, -4.21000011e-02,\n",
       "        9.99999978e-03,  1.48100004e-01, -6.36999980e-02,  6.48000017e-02,\n",
       "        7.37000033e-02,  2.23499998e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix[912][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What have we shown by this?**   \n",
    "That we have correctly mapped given sequence of words into an embedding matrix that will be used in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sequences, \n",
    "    labels, \n",
    "    test_size=0.10, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.model import FakeNewsDetectionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 3360."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can finally train our model on the sample of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/3\n",
      "270/270 [==============================] - 378s 1s/sample - loss: 0.6401 - accuracy: 0.6444 - val_loss: 0.5855 - val_accuracy: 0.7000\n",
      "Epoch 2/3\n",
      "270/270 [==============================] - 387s 1s/sample - loss: 0.4960 - accuracy: 0.7778 - val_loss: 0.5677 - val_accuracy: 0.6333\n",
      "Epoch 3/3\n",
      "270/270 [==============================] - 388s 1s/sample - loss: 0.3519 - accuracy: 0.8704 - val_loss: 0.5397 - val_accuracy: 0.7000\n",
      "Model: \"fake_news_detection_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  5652900   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional multiple                  186880    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 5,848,101\n",
      "Trainable params: 195,201\n",
      "Non-trainable params: 5,652,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "model = FakeNewsDetectionNet(\n",
    "        dim_input=len(word_index),\n",
    "        dim_embeddings=300,\n",
    "        embeddings=embeddings_matrix,\n",
    "        lstm_units = 64,\n",
    "        num_hidden_layers = 1\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "        histogram_freq=1,\n",
    "        profile_batch=0\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Model have been constructed and tested on small sample on data (proof of concept). Now we can use it in training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
