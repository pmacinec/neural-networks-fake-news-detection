{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake news detection\n",
    "\n",
    "**Authors:** Peter Mačinec, Simona Miková"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed/dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use only sample of data for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339022</th>\n",
       "      <td>alive! catholic monthly newspaper ireland by n...</td>\n",
       "      <td>unreliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314059</th>\n",
       "      <td>new imaging technique could make brain tumor r...</td>\n",
       "      <td>reliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299697</th>\n",
       "      <td>last september i sent you an e alert about a s...</td>\n",
       "      <td>unreliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354092</th>\n",
       "      <td>the answer to this question is complicated, so...</td>\n",
       "      <td>reliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272561</th>\n",
       "      <td>for a trip to the er, some are opting for uber...</td>\n",
       "      <td>reliable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body       label\n",
       "339022  alive! catholic monthly newspaper ireland by n...  unreliable\n",
       "314059  new imaging technique could make brain tumor r...    reliable\n",
       "299697  last september i sent you an e alert about a s...  unreliable\n",
       "354092  the answer to this question is complicated, so...    reliable\n",
       "272561  for a trip to the er, some are opting for uber...    reliable"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels need to be encoded to 0 and 1 (One hot encoding), so our model will be able to understand them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_encoded'] = df['label'].apply(lambda label: 1 if label == 'unreliable' else 0)\n",
    "labels = np.asarray(df['label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the shape of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.preprocessing import get_sequences_and_word_index\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum number of words to preserve will be set to 20000 for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we need to generate sequences and word index table from article body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequences, word_index = get_sequences_and_word_index(df['body'], max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s have a look at number of unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18549"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And shape of input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 4886)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading fastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.fasttext import read_fasttext_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read fastText model from .vec file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fasttext = read_fasttext_model('../models/fasttext/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999995, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasttext), len(fasttext['work'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings dimension (length of vectors) will be set to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.preprocessing import get_embeddings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to get embeddings matrix from acquired word indexes and pre-trained embeddings (in our case fastText)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words not found in pre-trained embeddings: 1951\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_matrix = get_embeddings_matrix(word_index, fasttext, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19401, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check if index in sequences match with some randomly choosen word (for example word 'tumor')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will find given word in word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['tumor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check fasttext value for this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0094, -0.2403, -0.0307,  0.066 , -0.1379,  0.0199,  0.004 ,\n",
       "       -0.1303,  0.3053,  0.1848,  0.0616, -0.0794,  0.0279, -0.1055,\n",
       "       -0.1279,  0.0466,  0.0365,  0.0953, -0.091 , -0.1541, -0.5253,\n",
       "        0.0725, -0.0753,  0.2322, -0.0999, -0.0431, -0.1307,  0.0884,\n",
       "       -0.0428, -0.0842, -0.0598, -0.0334, -0.0154,  0.0476,  0.309 ,\n",
       "       -0.1065,  0.1463, -0.0541, -0.0502, -0.0209,  0.0089,  0.1604,\n",
       "        0.1508,  0.153 ,  0.0445,  0.0035, -0.0885, -0.0259,  0.1005,\n",
       "       -0.1053], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext['tumor'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare it to value at given index in embeddings_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0094    , -0.2403    , -0.0307    ,  0.066     , -0.13789999,\n",
       "        0.0199    ,  0.004     , -0.1303    ,  0.3053    ,  0.1848    ,\n",
       "        0.0616    , -0.0794    ,  0.0279    , -0.1055    , -0.1279    ,\n",
       "        0.0466    ,  0.0365    ,  0.0953    , -0.091     , -0.1541    ,\n",
       "       -0.52530003,  0.0725    , -0.0753    ,  0.2322    , -0.0999    ,\n",
       "       -0.0431    , -0.13070001,  0.0884    , -0.0428    , -0.0842    ,\n",
       "       -0.0598    , -0.0334    , -0.0154    ,  0.0476    ,  0.30899999,\n",
       "       -0.1065    ,  0.1463    , -0.0541    , -0.0502    , -0.0209    ,\n",
       "        0.0089    ,  0.1604    ,  0.1508    ,  0.153     ,  0.0445    ,\n",
       "        0.0035    , -0.0885    , -0.0259    ,  0.1005    , -0.1053    ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix[912][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What have we shown by this?**   \n",
    "That we have correctly mapped given sequence of words into an embedding matrix that will be used in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.model import FakeNewsDetectionNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can finally train our model on the sample of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "270/270 [==============================] - 305s 1s/sample - loss: 0.6314 - accuracy: 0.6444 - val_loss: 0.6001 - val_accuracy: 0.6667\n",
      "Model: \"fake_news_detection_net_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  5564700   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection multiple                  186880    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 5,759,901\n",
      "Trainable params: 195,201\n",
      "Non-trainable params: 5,564,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "model = FakeNewsDetectionNet(\n",
    "        dim_input=len(word_index),\n",
    "        dim_embeddings=300,\n",
    "        embeddings=embeddings_matrix,\n",
    "        lstm_units = 64,\n",
    "        num_hidden_layers = 1\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "        histogram_freq=1,\n",
    "        profile_batch=0\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train.reshape((-1,1)),\n",
    "    batch_size=16,\n",
    "    validation_data=(X_test, y_test.reshape((-1,1))),\n",
    "    callbacks=callbacks,\n",
    "    epochs=1\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
