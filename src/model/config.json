{
  "batch_size": 16,
  "learning_rate": 0.01,
  "num_hidden_layers": 1,
  "epochs": 5,
  "max_words": 30000,
  "max_seq_len": 2500,
  "lstm_units": 64
}